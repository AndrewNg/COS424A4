{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment Score Prediction\n",
    "## Stefan Keselj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this file is to extract comment features from the Kaggle May 2015 Data and then use non-score features to predict score. Note that the features described in the previous sentence are intermediate features, like a specific comment represented as a string, which will then be further processed into finer features like a bag-of-words vector of that comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd; import numpy as np; \n",
    "from scipy.sparse import csr_matrix\n",
    "import nltk\n",
    "import math; import time\n",
    "import enchant; english_dict = enchant.Dict(\"en_US\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from HTMLParser import HTMLParser\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, \\\n",
    "                             stop_words = None, max_features = 5000) \n",
    "from stemming.porter2 import stem\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib import pylab\n",
    "%matplotlib inline\n",
    "#%pylab inline\n",
    "#pylab.rcParams['figure.figsize'] = (20, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (0,1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# load my data (andrew's data preprocessed for this task)\n",
    "dftrain = pd.read_csv('data/train_data_stef.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>There are a lot of small tournaments in CS:GO ...</td>\n",
       "      <td>21</td>\n",
       "      <td>GlobalOffensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I actually managed the Chilkoot trail with a 4...</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Bruh</td>\n",
       "      <td>1</td>\n",
       "      <td>nba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[Here you go](http://ftve3100-i.akamaihd.net/h...</td>\n",
       "      <td>1</td>\n",
       "      <td>nba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Retailers will just jack up the prices across ...</td>\n",
       "      <td>0</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Kobe 392 attempts this year and Jason Williams...</td>\n",
       "      <td>1</td>\n",
       "      <td>nba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>China also invented the e-cig and many other i...</td>\n",
       "      <td>6</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Vampire hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[**Foreigners who want to Understand**](http:/...</td>\n",
       "      <td>926</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>&amp;gt; OW is flawed,\\n no its not, if it has les...</td>\n",
       "      <td>0</td>\n",
       "      <td>GlobalOffensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                               body score  \\\n",
       "0          0  There are a lot of small tournaments in CS:GO ...    21   \n",
       "1          1  I actually managed the Chilkoot trail with a 4...     1   \n",
       "2          2                                               Bruh     1   \n",
       "3          3  [Here you go](http://ftve3100-i.akamaihd.net/h...     1   \n",
       "4          4  Retailers will just jack up the prices across ...     0   \n",
       "5          5  Kobe 392 attempts this year and Jason Williams...     1   \n",
       "6          6  China also invented the e-cig and many other i...     6   \n",
       "7          7                                    Vampire hunter      1   \n",
       "8          8  [**Foreigners who want to Understand**](http:/...   926   \n",
       "9          9  &gt; OW is flawed,\\n no its not, if it has les...     0   \n",
       "\n",
       "         subreddit  \n",
       "0  GlobalOffensive  \n",
       "1             pics  \n",
       "2              nba  \n",
       "3              nba  \n",
       "4        worldnews  \n",
       "5              nba  \n",
       "6        worldnews  \n",
       "7             pics  \n",
       "8        worldnews  \n",
       "9  GlobalOffensive  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dft_pic = dftrain[dftrain.subreddit==\"pics\"]\n",
    "dft_wne = dftrain[dftrain.subreddit==\"worldnews\"]\n",
    "dft_fun = dftrain[dftrain.subreddit==\"funny\"]\n",
    "dft_aww = dftrain[dftrain.subreddit==\"aww\"]\n",
    "dft_gof = dftrain[dftrain.subreddit==\"aww\"]\n",
    "dft_nba = dftrain[dftrain.subreddit==\"nba\"]\n",
    "dft_cje = dftrain[dftrain.subreddit==\"circlejerk\"]\n",
    "dft_list = [dft_pic, dft_nba, dft_wne, dft_fun, dft_aww, dft_gof, dft_cje]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I actually managed the Chilkoot trail with a 4...</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Vampire hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Only Animals with 4 legs</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>That quote could not be more ironic.</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>And with one piece of propaganda Trump instill...</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>I thought the final picture was gonna be them ...</td>\n",
       "      <td>0</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>You left handed?</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>You just said its ok for people to spill acros...</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>Until we inevitably come up with the fake stor...</td>\n",
       "      <td>0</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>Oh. True.</td>\n",
       "      <td>3</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               body score  \\\n",
       "1           1  I actually managed the Chilkoot trail with a 4...     1   \n",
       "7           7                                    Vampire hunter      1   \n",
       "11         11                           Only Animals with 4 legs     1   \n",
       "20         20              That quote could not be more ironic.      1   \n",
       "24         24  And with one piece of propaganda Trump instill...     1   \n",
       "25         25  I thought the final picture was gonna be them ...     0   \n",
       "32         32                                   You left handed?     1   \n",
       "36         36  You just said its ok for people to spill acros...     1   \n",
       "40         40  Until we inevitably come up with the fake stor...     0   \n",
       "48         48                                          Oh. True.     3   \n",
       "\n",
       "   subreddit  \n",
       "1       pics  \n",
       "7       pics  \n",
       "11      pics  \n",
       "20      pics  \n",
       "24      pics  \n",
       "25      pics  \n",
       "32      pics  \n",
       "36      pics  \n",
       "40      pics  \n",
       "48      pics  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft_pic.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check if a string is a number \n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "# remove non-english words, stop-words, punctuation\n",
    "def clean_comment(sentence):\n",
    "    try:\n",
    "        sentence = sentence.decode('utf-8')\n",
    "        # remove escape sequences, e.g. &gt becomes >\n",
    "        parser = HTMLParser(); sentence = parser.unescape(sentence)\n",
    "        # tokenize\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        tokens_no_punct = tokenizer.tokenize(sentence)\n",
    "        # remove punctuation, numbers, stopwords, and non-English; return stemmed and lowercase\n",
    "        meaningful_words = [stem(word.lower()) for word in tokens_no_punct \n",
    "                            if not is_number(word)\n",
    "                            and word.lower() not in stopwords.words('english') \n",
    "                            and english_dict.check(word.lower())]\n",
    "        return (\" \".join( meaningful_words ))\n",
    "    # catch nans\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  100  1000  10000  100000  200000 "
     ]
    }
   ],
   "source": [
    "dft = dft_wne\n",
    "# clean all of the comments in the subreddit 'pics'\n",
    "c = 0; start_time = time.time()\n",
    "dft_clean = []\n",
    "for row_index, row in dft.iterrows():\n",
    "    dft_clean.append(clean_comment(row['body']))\n",
    "    c += 1\n",
    "    if c==10 or c==100 or c==1000 or c==10000 or c%100000==0:\n",
    "        print (str(c) + \" \"),\n",
    "print time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build a bag of words representation \n",
    "dtf_BOW = vectorizer.fit_transform(dft_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save it to a file\n",
    "save_sparse_csr(\"data/wne_BOW.npz\",dtf_BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test that we saved everything correctly\n",
    "dft_pic_BWO = load_sparse_csr(\"data/pic_BOW.npz\")\n",
    "b = load_sparse_csr(\"data/wne_BOW.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtf_pic_features_array = dtf_pic_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 5000)\n",
      "(400000,)\n",
      "(145749, 5000)\n",
      "(145749,)\n"
     ]
    }
   ],
   "source": [
    "print shape(dtf_pic_features[0:400000])\n",
    "print shape(dft_pic['score'][0:400000])\n",
    "print shape(dtf_pic_features[400000:])\n",
    "print shape(dft_pic['score'][400000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Word to vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The bag of words representation is convenient for larger bodies of text like articles or books, but might not be best suited for comment data. Comment data is small and semantically packed, we need some way of accessing the intrinsic meaning of a comment from the few words provided. To accomplish this we will use the Word to Vector model, which incoporates deep learning into our existing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prediction Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.74660403188\n",
      "11.30064\n",
      "22.6266525432\n",
      "11685.3415595\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "X_train = dtf_pic_features[0:400000]\n",
    "Y_train = np.array(dft_pic['score'][0:400000])\n",
    "lm = linear_model.LinearRegression()\n",
    "lm_fitted = lm.fit(X_train, Y_train)\n",
    "#test\n",
    "X_test = dtf_pic_features[400000:]\n",
    "Y_true = dft_pic['score'][400000:]\n",
    "Y_pred = lm_fitted.predict(X_test)\n",
    "#evaluate\n",
    "relative_error = 0\n",
    "for i in range(0,len(Y_pred)):\n",
    "    scale = float(Y_true.iloc[i])\n",
    "    if abs(float(Y_true.iloc[i])) < 1:\n",
    "        scale = 1\n",
    "    relative_error += (float(Y_pred[i])-float(Y_true.iloc[i]))/scale/len(Y_pred)\n",
    "print relative_error\n",
    "print metrics.median_absolute_error(Y_true, Y_pred)\n",
    "print metrics.mean_absolute_error(Y_true, Y_pred)\n",
    "print metrics.mean_squared_error(Y_true, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "29.4182398223\n"
     ]
    }
   ],
   "source": [
    "plt.hist(dftest['sender'].values,10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.2 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of fitting a regressor to our data, a classifier might be better. This is because the number of upvotes of a comment's parent post greatly effecsts its success, but we don't have access to this latent variable. It causes the very popular comments to be skewed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Word to vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The bag of words representation is convenient for larger bodies of text like articles or books, but might not be best suited for comment data. Comment data is small and semantically packed, we need some way of accessing the intrinsic meaning of a comment from the few words provided. To accomplish this we will use the Word to Vector model, which incoporates deep learning into our existing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Skip-thought vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 2grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Utilities and Sketchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_sparse_csr(filename,array):\n",
    "    np.savez(filename,data = array.data ,indices=array.indices,\n",
    "             indptr =array.indptr, shape=array.shape )\n",
    "\n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return csr_matrix((  loader['data'], loader['indices'], loader['indptr']),\n",
    "                         shape = loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean = []\n",
    "#for i in xrange(0,100):\n",
    "#    print i\n",
    "#    print clean_comment(dftrain.iloc[i]['body'])\n",
    "#    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for i in range(0,10):\n",
    "#    print i\n",
    "#    print df_pic.iloc[i]['score']\n",
    "#    print df_pic.iloc[i]['body']\n",
    "#    print str(clean_comment(df_pic.iloc[i]['body']))\n",
    "#    print \"\"\n",
    "\n",
    "    # check if a string is only ascii characters\n",
    "    #def is_ascii(s)\n",
    "    #    try:\n",
    "    #        s.decode('utf-8')\n",
    "    #        return True\n",
    "    #    except UnicodeDecodeError:\n",
    "    #        print s\n",
    "    #        return False\n",
    "    # main logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
