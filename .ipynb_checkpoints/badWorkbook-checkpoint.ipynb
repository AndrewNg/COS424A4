{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment Score Prediction\n",
    "## Stefan Keselj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this file is to extract comment features from the Kaggle May 2015 Data and then use non-score features to predict score. Note that the features described in the previous sentence are intermediate features, like a specific comment represented as a string, which will then be further processed into finer features like a bag-of-words vector of that comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd; import numpy as np; \n",
    "from scipy.sparse import csr_matrix\n",
    "import nltk\n",
    "from unidecode import unidecode\n",
    "import math; import time\n",
    "import enchant; english_dict = enchant.Dict(\"en_US\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from HTMLParser import HTMLParser\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, \\\n",
    "                             stop_words = None, max_features = 5000) \n",
    "from stemming.porter2 import stem\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib import pylab\n",
    "%matplotlib inline\n",
    "#%pylab inline\n",
    "#pylab.rcParams['figure.figsize'] = (20, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (0,1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# load my data (andrew's data preprocessed for this task)\n",
    "dftrain = pd.read_csv('data/train_data_stef.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>There are a lot of small tournaments in CS:GO ...</td>\n",
       "      <td>21</td>\n",
       "      <td>GlobalOffensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I actually managed the Chilkoot trail with a 4...</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Bruh</td>\n",
       "      <td>1</td>\n",
       "      <td>nba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[Here you go](http://ftve3100-i.akamaihd.net/h...</td>\n",
       "      <td>1</td>\n",
       "      <td>nba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Retailers will just jack up the prices across ...</td>\n",
       "      <td>0</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Kobe 392 attempts this year and Jason Williams...</td>\n",
       "      <td>1</td>\n",
       "      <td>nba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>China also invented the e-cig and many other i...</td>\n",
       "      <td>6</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Vampire hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[**Foreigners who want to Understand**](http:/...</td>\n",
       "      <td>926</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>&amp;gt; OW is flawed,\\n no its not, if it has les...</td>\n",
       "      <td>0</td>\n",
       "      <td>GlobalOffensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                               body score  \\\n",
       "0          0  There are a lot of small tournaments in CS:GO ...    21   \n",
       "1          1  I actually managed the Chilkoot trail with a 4...     1   \n",
       "2          2                                               Bruh     1   \n",
       "3          3  [Here you go](http://ftve3100-i.akamaihd.net/h...     1   \n",
       "4          4  Retailers will just jack up the prices across ...     0   \n",
       "5          5  Kobe 392 attempts this year and Jason Williams...     1   \n",
       "6          6  China also invented the e-cig and many other i...     6   \n",
       "7          7                                    Vampire hunter      1   \n",
       "8          8  [**Foreigners who want to Understand**](http:/...   926   \n",
       "9          9  &gt; OW is flawed,\\n no its not, if it has les...     0   \n",
       "\n",
       "         subreddit  \n",
       "0  GlobalOffensive  \n",
       "1             pics  \n",
       "2              nba  \n",
       "3              nba  \n",
       "4        worldnews  \n",
       "5              nba  \n",
       "6        worldnews  \n",
       "7             pics  \n",
       "8        worldnews  \n",
       "9  GlobalOffensive  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dft_pic = dftrain[dftrain.subreddit==\"pics\"]\n",
    "dft_wne = dftrain[dftrain.subreddit==\"worldnews\"]\n",
    "dft_fun = dftrain[dftrain.subreddit==\"funny\"]\n",
    "dft_aww = dftrain[dftrain.subreddit==\"aww\"]\n",
    "dft_gof = dftrain[dftrain.subreddit==\"aww\"]\n",
    "dft_nba = dftrain[dftrain.subreddit==\"nba\"]\n",
    "dft_cje = dftrain[dftrain.subreddit==\"circlejerk\"]\n",
    "dft_list = [dft_pic, dft_nba, dft_wne, dft_fun, dft_aww, dft_gof, dft_cje]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I actually managed the Chilkoot trail with a 4...</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Vampire hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Only Animals with 4 legs</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>That quote could not be more ironic.</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>And with one piece of propaganda Trump instill...</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>I thought the final picture was gonna be them ...</td>\n",
       "      <td>0</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>You left handed?</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>You just said its ok for people to spill acros...</td>\n",
       "      <td>1</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>Until we inevitably come up with the fake stor...</td>\n",
       "      <td>0</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>Oh. True.</td>\n",
       "      <td>3</td>\n",
       "      <td>pics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               body score  \\\n",
       "1           1  I actually managed the Chilkoot trail with a 4...     1   \n",
       "7           7                                    Vampire hunter      1   \n",
       "11         11                           Only Animals with 4 legs     1   \n",
       "20         20              That quote could not be more ironic.      1   \n",
       "24         24  And with one piece of propaganda Trump instill...     1   \n",
       "25         25  I thought the final picture was gonna be them ...     0   \n",
       "32         32                                   You left handed?     1   \n",
       "36         36  You just said its ok for people to spill acros...     1   \n",
       "40         40  Until we inevitably come up with the fake stor...     0   \n",
       "48         48                                          Oh. True.     3   \n",
       "\n",
       "   subreddit  \n",
       "1       pics  \n",
       "7       pics  \n",
       "11      pics  \n",
       "20      pics  \n",
       "24      pics  \n",
       "25      pics  \n",
       "32      pics  \n",
       "36      pics  \n",
       "40      pics  \n",
       "48      pics  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft_pic.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# check if a string is a number \n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "# remove non-english words, stop-words, punctuation\n",
    "def clean_comment(sentence, isRemoveStop):\n",
    "    try:\n",
    "        sentence = unicode(unidecode(sentence.decode('utf-8')))\n",
    "        # remove escape sequences, e.g. &gt becomes >\n",
    "        parser = HTMLParser(); sentence = parser.unescape(sentence)\n",
    "        # tokenize\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        tokens_no_punct = tokenizer.tokenize(sentence)\n",
    "        # remove punctuation, numbers, stopwords, and non-English; return stemmed and lowercase\n",
    "        meaningful_words = [stem(word.lower()) for word in tokens_no_punct \n",
    "                            if not is_number(word)\n",
    "                            and ((not isRemoveStop) or (word.lower() not in stopwords.words('english'))) \n",
    "                            and english_dict.check(word.lower())]\n",
    "        return (\" \".join( meaningful_words ))\n",
    "    # catch nans\n",
    "    except:\n",
    "        print sentence\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  100  1000  10000  100000 "
     ]
    }
   ],
   "source": [
    "# clean all of the comments in the subreddit 'pics'\n",
    "c = 0; start_time = time.time()\n",
    "dft_wne_clean_nstop = []\n",
    "for row_index, row in dft_wne.iterrows():\n",
    "    dft_wne_clean_nstop.append(clean_comment(row['body'],True)) ### Important: TRUE\n",
    "    c += 1\n",
    "    if c==10 or c==100 or c==1000 or c==10000 or c%100000==0:\n",
    "        print (str(c) + \" \"),\n",
    "print time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the cleaned text to file (later)\n",
    "se_wne_clean_nstop = pd.Series(dft_wne_clean_nstop)\n",
    "se_wne_clean_nstop.to_csv('data/wne_clean_nstop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build a bag of words representation \n",
    "dtf_BOW = vectorizer.fit_transform(dft_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save it to a file\n",
    "save_sparse_csr(\"data/wne_BOW.npz\",dtf_BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test that we saved everything correctly, these are the ones that are done so far\n",
    "dft_pic_BOW = load_sparse_csr(\"data/pic_BOW.npz\")\n",
    "dft_wne_BOW = load_sparse_csr(\"data/wne_BOW.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dft_pic_BOW_a = dft_pic_BOW.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Word to vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The bag of words representation is convenient for larger bodies of text like articles or books, but might not be best suited for comment data. Comment data is small and semantically packed, we need some way of accessing the intrinsic meaning of a comment from the few words provided. To accomplish this we will use the Word to Vector model, which incoporates deep learning into our existing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The first step is to build a list of the words which filters out numbers and punctuation, but has stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  100  1000  10000  nan\n",
      "nan\n",
      "100000  nan\n",
      "200000  nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "300000  nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "400000  nan\n",
      "nan\n",
      "nan\n",
      "500000  nan\n",
      "nan\n",
      "1885.07237506\n"
     ]
    }
   ],
   "source": [
    "# clean all of the comments in the subreddit 'worldnews'\n",
    "c = 0; start_time = time.time()\n",
    "dft_wne_clean_stop = []\n",
    "for row_index, row in dft_wne.iterrows():\n",
    "    dft_wne_clean_stop.append(clean_comment(row['body'],False)) ### Important: FALSE\n",
    "    c += 1\n",
    "    if c==10 or c==100 or c==1000 or c==10000 or c%100000==0:\n",
    "        print (str(c) + \" \"),\n",
    "print time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We absolutely have to store this, because it takes forever every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "se_wne_clean_stop = pd.Series(dft_wne_clean_nstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character u'\\xe9' in position 19: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-a58f4dd733b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mse_wne_clean_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/wne_clean_stop.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/sk/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path, index, sep, na_rep, float_format, header, index_label, mode, nanRep, encoding, date_format, decimal)\u001b[0m\n\u001b[1;32m   2596\u001b[0m                            \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnanRep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnanRep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2597\u001b[0m                            \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2598\u001b[0;31m                            decimal=decimal)\n\u001b[0m\u001b[1;32m   2599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2600\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sk/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal, **kwds)\u001b[0m\n\u001b[1;32m   1341\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1343\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sk/anaconda/lib/python2.7/site-packages/pandas/core/format.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sk/anaconda/lib/python2.7/site-packages/pandas/core/format.pyc\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1649\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1651\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sk/anaconda/lib/python2.7/site-packages/pandas/core/format.pyc\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m   1675\u001b[0m                                         quoting=self.quoting)\n\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1677\u001b[0;31m         \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_csv_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[0;31m# from collections import namedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/lib.pyx\u001b[0m in \u001b[0;36mpandas.lib.write_csv_rows (pandas/lib.c:19470)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character u'\\xe9' in position 19: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "se_wne_clean_stop.to_csv('data/wne_clean_stop.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prediction Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-58e3798255f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtf_pic_BOW_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m400000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdft_pic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m400000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtf_pic_BOW_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m400000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdft_pic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m400000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shape' is not defined"
     ]
    }
   ],
   "source": [
    "print shape(dtf_pic_BOW_a[0:400000])\n",
    "print shape(dft_pic['score'][0:400000])\n",
    "print shape(dtf_pic_BOW_a[400000:])\n",
    "print shape(dft_pic['score'][400000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.74660403188\n",
      "11.30064\n",
      "22.6266525432\n",
      "11685.3415595\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "X_train = dtf_pic_features[0:400000]\n",
    "Y_train = np.array(dft_pic['score'][0:400000])\n",
    "lm = linear_model.LinearRegression()\n",
    "lm_fitted = lm.fit(X_train, Y_train)\n",
    "#test\n",
    "X_test = dtf_pic_features[400000:]\n",
    "Y_true = dft_pic['score'][400000:]\n",
    "Y_pred = lm_fitted.predict(X_test)\n",
    "#evaluate\n",
    "relative_error = 0\n",
    "for i in range(0,len(Y_pred)):\n",
    "    scale = float(Y_true.iloc[i])\n",
    "    if abs(float(Y_true.iloc[i])) < 1:\n",
    "        scale = 1\n",
    "    relative_error += (float(Y_pred[i])-float(Y_true.iloc[i]))/scale/len(Y_pred)\n",
    "print relative_error\n",
    "print metrics.median_absolute_error(Y_true, Y_pred)\n",
    "print metrics.mean_absolute_error(Y_true, Y_pred)\n",
    "print metrics.mean_squared_error(Y_true, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "29.4182398223\n"
     ]
    }
   ],
   "source": [
    "plt.hist(dftest['sender'].values,10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.2 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of fitting a regressor to our data, a classifier might be better. This is because the number of upvotes of a comment's parent post greatly effecsts its success, but we don't have access to this latent variable. It causes the very popular comments to be skewed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Skip-thought vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 2grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Utilities and Sketching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_sparse_csr(filename,array):\n",
    "    np.savez(filename,data = array.data ,indices=array.indices,\n",
    "             indptr =array.indptr, shape=array.shape )\n",
    "\n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return csr_matrix((  loader['data'], loader['indices'], loader['indptr']),\n",
    "                         shape = loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# an experiment\n",
    "df1 = DataFrame(np.random.randn(10, 4), columns=['a', 'b', 'c', 'd'])\n",
    "mask = df1.applymap(lambda x: x <-0.7)\n",
    "df1 = df1[-mask.any(axis=1)]\n",
    "sLength = len(df1['a'])\n",
    "df1['e'] = Series(np.random.randn(sLength), index=df1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean = []\n",
    "#for i in xrange(0,100):\n",
    "#    print i\n",
    "#    print clean_comment(dftrain.iloc[i]['body'])\n",
    "#    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for i in range(0,10):\n",
    "#    print i\n",
    "#    print df_pic.iloc[i]['score']\n",
    "#    print df_pic.iloc[i]['body']\n",
    "#    print str(clean_comment(df_pic.iloc[i]['body']))\n",
    "#    print \"\"\n",
    "\n",
    "# check if a string is only ascii characters\n",
    "def is_ascii(s):\n",
    "    try:\n",
    "        s.decode('ascii')\n",
    "        return True\n",
    "    except:\n",
    "        print s\n",
    "        return False\n",
    "    # main logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(dft_wne_clean_nstop)):\n",
    "    if (not is_ascii(dft_wne_clean_nstop[i])):\n",
    "        print i\n",
    "        break\n",
    "print dft_wne_clean_nstop[89]\n",
    "print clean_comment(dft_wne_clean_nstop[89],True)\n",
    "print clean_comment(dft_wne_clean_nstop[89],False)\n",
    "print type(clean_comment(dft_wne_clean_nstop[89],True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
