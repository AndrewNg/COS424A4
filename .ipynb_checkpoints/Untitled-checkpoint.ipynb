{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Comment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd; import numpy as np; \n",
    "from scipy.sparse import csr_matrix\n",
    "import nltk\n",
    "from unidecode import unidecode\n",
    "import math; import time\n",
    "# import enchant; english_dict = enchant.Dict(\"en_US\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from html.parser import HTMLParser\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "# from stemming.porter2 import stem\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, \\\n",
    "                             stop_words = None, max_features = 5000) \n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib import pylab\n",
    "%matplotlib inline\n",
    "#%pylab inline\n",
    "#pylab.rcParams['figure.figsize'] = (20, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import cleaned comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftrain = pd.read_csv(\"data/finalnostop.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dft_pic = dftrain[dftrain.subreddit==\"pics\"]\n",
    "dft_wne = dftrain[dftrain.subreddit==\"worldnews\"]\n",
    "dft_fun = dftrain[dftrain.subreddit==\"funny\"]\n",
    "dft_aww = dftrain[dftrain.subreddit==\"aww\"]\n",
    "dft_gof = dftrain[dftrain.subreddit==\"aww\"]\n",
    "dft_nba = dftrain[dftrain.subreddit==\"nba\"]\n",
    "dft_cje = dftrain[dftrain.subreddit==\"circlejerk\"]\n",
    "dft_all = [dft_pic, dft_nba, dft_wne, dft_fun, dft_aww, dft_gof, dft_cje]\n",
    "#dft_all_BOW = [dft_pic_BOW, dft_nba_BOW, dft_wne_BOW, dft_fun_BOW, dft_aww_BOW, dft_gof_BOW, dft_cje_BOW]\n",
    "#dft_all_TFI = [dft_pic_TFI, dft_nba_TFI, dft_wne_TFI, dft_fun_TFI, dft_aww_TFI, dft_gof_TFI, dft_cje_TFI]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dft = dft_pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove nans\n",
    "def remove_nan(s):\n",
    "    try:\n",
    "        f = float(s)\n",
    "        if math.isnan(f):\n",
    "            return \"\"\n",
    "    except:\n",
    "        return s\n",
    "sentences = []\n",
    "for row in dft['body']:\n",
    "    sentences.append(remove_nan(row)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(remove_nan(str(float('nan'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bag of words\n",
    "vectorizer_count = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, \\\n",
    "                             stop_words = None, max_features = 5000) \n",
    "dft_BOW = vectorizer_count.fit_transform(sentences)\n",
    "dft_BOW_a = dft_BOW.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TF_IDF\n",
    "vectorizer_tfid = TfidfVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, \\\n",
    "                             stop_words = None, max_features = 5000) \n",
    "dft_TFI = vectorizer_tfid.fit_transform(sentences)\n",
    "dft_TFI_a = dft_TFI.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(dft['score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(dft['score'],21,range=[-10, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we will set the following boundaries according to score:\n",
    "\n",
    "Bad: < 0\n",
    "\n",
    "Neutral: 0, 1\n",
    "\n",
    "Good: 2, 3, 4, 5\n",
    "\n",
    "Very Good: > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(dft['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# categorize each comment by score\n",
    "def categorize(score):\n",
    "    if score<0:\n",
    "        return 0\n",
    "    if score==0 or score==1:\n",
    "        return 1\n",
    "    elif score==2 or score==3 or score==4 or score==5:\n",
    "        return 2\n",
    "    elif score>5:\n",
    "        return 3\n",
    "    else:\n",
    "        return -1\n",
    "labels = []\n",
    "for row in dft['score']:\n",
    "    labels.append(categorize(row)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(labels,n_folds=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.shape(dft_BOW_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = data[:,train_index], data[:,test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
